{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2305c786-229a-4cc0-b0c3-d214cf791d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import face_recognition\n",
    "from IPython.display import display, Image, clear_output\n",
    "from arango import ArangoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa3872-5358-4cb1-9372-8bd8bdc9496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ArangoClient(hosts=\"http://localhost:8529\")\n",
    "\n",
    "db = client.db(\"Shoptaki-recog\", username=\"root\", password=\"openSesame\")\n",
    "\n",
    "people = db.collection(\"people\")\n",
    "people.add_index({'type': 'persistent', 'fields': ['name'],})\n",
    "people.insert({\"name\": \"Gangey\", \"path\": \"photo.jpeg\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21010f87-fa5b-4366-a201-92024b538fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_static_image_encoding(image_path):\n",
    "    static_img = face_recognition.load_image_file(image_path)\n",
    "    return face_recognition.face_encodings(static_img)[0]\n",
    "\n",
    "def show_live_video():\n",
    "    static_image_encoding = load_static_image_encoding(\"photo.jpeg\")\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to access the webcam.\")\n",
    "        return\n",
    "\n",
    "    with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.2) as face_detection:\n",
    "        try:\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(\"Error: Failed to capture image.\")\n",
    "                    break\n",
    "\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                results = face_detection.process(frame_rgb)\n",
    "\n",
    "                if results.detections:\n",
    "                    for detection in results.detections:\n",
    "                        # Extract bounding box information\n",
    "                        h, w, _ = frame_rgb.shape\n",
    "                        try:\n",
    "                            top = int(detection.location_data.relative_bounding_box.ymin * h)\n",
    "                            right = int((detection.location_data.relative_bounding_box.xmin + detection.location_data.relative_bounding_box.width) * w)\n",
    "                            bottom = int((detection.location_data.relative_bounding_box.ymin + detection.location_data.relative_bounding_box.height) * h)\n",
    "                            left = int(detection.location_data.relative_bounding_box.xmin * w)\n",
    "                            face_roi = frame_rgb[top:bottom, left:right]\n",
    "\n",
    "                            # Convert the face region to BGR color (required by face_recognition)\n",
    "                            face_roi_bgr = cv2.cvtColor(face_roi, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                            # Detect face locations and encodings in the face ROI\n",
    "                            face_locations = face_recognition.face_locations(face_roi_bgr)\n",
    "                            face_encodings = face_recognition.face_encodings(face_roi_bgr, face_locations)\n",
    "\n",
    "                            if face_encodings:\n",
    "                                face_encoding = face_encodings[0]\n",
    "                                results = face_recognition.compare_faces([static_image_encoding], face_encoding)\n",
    "                                if results[0]:\n",
    "                                    print(\"Match found!\")\n",
    "                                    break\n",
    "                                else:\n",
    "                                    print(\"No match\")\n",
    "\n",
    "                            mp_drawing.draw_detection(frame, detection)\n",
    "                            clear_output(wait=True)\n",
    "                            display(Image(data=cv2.imencode('.jpg', frame)[1].tobytes()))\n",
    "                        except AttributeError:\n",
    "                            print(\"Error: Could not extract bounding box information.\")\n",
    "                            continue\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39b6ed7-25d9-4f88-ae69-490c7b818d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
